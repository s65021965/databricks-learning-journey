{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This notebook documents the basic concepts of Delta Lake, including how data is\n",
        "stored in Delta format, how Delta tables are created, schema enforcement, and\n",
        "handling duplicate data using merge operations."
      ],
      "metadata": {
        "id": "ftrl23Q6GqMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction to Delta Lake\n",
        "\n",
        "Delta Lake is an open-source storage layer that brings reliability to data lakes.\n",
        "It provides ACID transactions, schema enforcement, and support for updates and\n",
        "deletes on top of Apache Spark."
      ],
      "metadata": {
        "id": "86Pm4P6cGvhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Converting CSV Data to Delta Format\n",
        "\n",
        "Raw CSV files do not support transactions and can lead to data inconsistency.\n",
        "Delta format stores data in a transactional manner, making it more reliable."
      ],
      "metadata": {
        "id": "mRzY6YADG01o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-wzn5-RF8Y0"
      },
      "outputs": [],
      "source": [
        "# Converting data to Delta format\n",
        "events.write.format(\"delta\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .save(\"/delta/events\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Creating Delta Tables (PySpark and SQL)\n",
        "\n",
        "Delta tables can be created using both PySpark and SQL so that different users\n",
        "such as data engineers and analysts can work with the same data."
      ],
      "metadata": {
        "id": "1adWRPpaG7QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Delta table using PySpark\n",
        "events.write.format(\"delta\") \\\n",
        "    .saveAsTable(\"events_table\")"
      ],
      "metadata": {
        "id": "oGxjvs5VG4mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Delta table using SQL\n",
        "CREATE TABLE events_delta\n",
        "USING DELTA\n",
        "AS SELECT * FROM events_table;"
      ],
      "metadata": {
        "id": "e0XdMqb5HTQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Schema Enforcement in Delta Lake\n",
        "\n",
        "Delta Lake enforces schema to prevent incompatible or incorrect data from being\n",
        "written into existing tables, ensuring data quality."
      ],
      "metadata": {
        "id": "zrox1BXnHZm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Attempt to write data with incompatible schema\n",
        "try:\n",
        "    wrong_schema_df.write.format(\"delta\") \\\n",
        "        .mode(\"append\") \\\n",
        "        .save(\"/delta/events\")\n",
        "except Exception as e:\n",
        "    print(\"Schema enforcement error:\", e)"
      ],
      "metadata": {
        "id": "eJfdzr_PHd6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Handling Duplicate Inserts using MERGE\n",
        "\n",
        "Delta Lake supports MERGE operations to avoid duplicate records when pipelines\n",
        "are re-run or data is reprocessed."
      ],
      "metadata": {
        "id": "rFWgkCKTJFFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MERGE INTO events_delta t\n",
        "USING new_events s\n",
        "ON t.id = s.id\n",
        "WHEN MATCHED THEN UPDATE SET *"
      ],
      "metadata": {
        "id": "vmRjC0hSJHoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Key Takeaways\n",
        "\n",
        "Delta Lake enhances data lakes by adding reliability, schema enforcement, and\n",
        "safe mechanisms for handling updates and duplicate data, making it suitable for\n",
        "production data pipelines."
      ],
      "metadata": {
        "id": "x4vPWF8NJNSa"
      }
    }
  ]
}